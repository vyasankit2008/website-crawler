# ğŸ•·ï¸ NestJS Website Crawler & Product Metadata Extractor

<p align="center">
  <a href="https://nestjs.com" target="_blank">
    <img src="https://nestjs.com/img/logo-small.svg" width="120" alt="NestJS Logo" />
  </a>
</p>

<p align="center">
  A scalable <strong>Website Crawling & Product Metadata Extraction</strong> service built using
  <a href="https://nestjs.com">NestJS</a>,
  <a href="https://pptr.dev/">Puppeteer</a>,
  <a href="https://cheerio.js.org/">Cheerio</a>,
  and <strong>PostgreSQL</strong>.
</p>

---

## ğŸ“Œ Description

This project extends the default **NestJS TypeScript starter** into a **production-ready website crawler** capable of:

- ğŸŒ Crawling websites via `sitemap.xml`
- ğŸ§ª Crawling individual product pages for debugging
- ğŸ§  Rendering JavaScript-heavy pages using Puppeteer
- ğŸ§¾ Extracting structured metadata using Cheerio
- ğŸ”„ Handling dynamic dropdown content (e.g. size-based product details)
- ğŸ§­ Generating dynamic breadcrumb levels
- ğŸ’¾ Persisting crawl results into PostgreSQL

---

## ğŸš€ Core Features

- âœ… Sitemap-based page discovery
- âœ… Direct single-page crawling (debug mode)
- âœ… JavaScript-rendered DOM support
- âœ… Dynamic breadcrumb level generation
- âœ… Product metadata extraction
- âœ… Size dropdown â†’ dynamic description extraction
- âœ… Crawl status tracking (`pending / done / failed`)
- âœ… Modular NestJS architecture

---

## ğŸ§° Tech Stack

| Layer       | Technology          |
| ----------- | ------------------- |
| Backend     | NestJS (TypeScript) |
| Scraping    | Puppeteer + Cheerio |
| Database    | PostgreSQL          |
| ORM         | TypeORM             |
| HTTP Client | Axios               |

---

## ğŸ“‚ Project Structure

```bash
src/
â”œâ”€â”€ app.module.ts
â”œâ”€â”€ main.ts
â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ crawler.controller.ts
â”‚   â”œâ”€â”€ crawler.service.ts
â”‚   â”œâ”€â”€ crawler.module.ts
â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”œâ”€â”€ website.entity.ts
â”‚   â”‚   â”œâ”€â”€ page.entity.ts
â”‚   â”‚   â””â”€â”€ page-metadata.entity.ts
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ page-loader.ts
â”‚       â”œâ”€â”€ metadata-extractor.ts
â”‚       â””â”€â”€ size-extractor.ts
```

---

## âš™ï¸ Environment Setup

### Quick Start

1. **Copy the example file:**
   ```bash
   cp .env.example .env
   ```

2. **Edit `.env`** and fill in your Supabase credentials

3. **See [ENV_SETUP.md](./ENV_SETUP.md)** for detailed instructions on getting your Supabase credentials

### Configuration Options

**Option 1: Supabase Pooler (Recommended)**
```env
DB_POOLER_HOST=aws-1-us-east-2.pooler.supabase.com
DB_POOLER_USER=postgres.deaohsesihodomvhqlxe
DB_POOLER_PORT=6543
DB_PASSWORD=your_password
DB_NAME=postgres
```

**Option 2: Direct Connection**
```env
DATABASE_HOST=db.deaohsesihodomvhqlxe.supabase.co
DATABASE_PORT=5432
DATABASE_USER=postgres
DATABASE_PASSWORD=your_password
DATABASE_NAME=postgres
DATABASE_SSL=true
```

**Note**: SSL is automatically enabled for remote hosts (Supabase). See [ENV_SETUP.md](./ENV_SETUP.md) for complete setup instructions.

---

## ğŸ“¦ Install Dependencies

```bash
npm install
```

---

## â–¶ï¸ Run the Application

```bash
# Development
npm run start:dev

# Production
npm run start:prod
```

---

## ğŸ”Œ API Usage (Postman)

### 1ï¸âƒ£ Register a Website (Sitemap Crawl)

**Endpoint**

```http
POST /crawler/register
```

**Request Body**

```json
{
  "websiteUrl": "https://valveman.com"
}
```

---

### 2ï¸âƒ£ Debug Single Page

**Endpoint**

```http
POST /crawler/debug-page
```

**Request Body**

```json
{
  "url": "https://valveman.com/products/2-1-2-apollo-94alf10901a/"
}
```

---

## ğŸ§ª Example Output

```json
{
  "productTitle": "2-1/2 Apollo Valve",
  "brand": "Apollo",
  "breadcrumbs": "Valves > Ball Valves > Manual > Test > Product Name",
  "sizes": {
    "2 inch": { "price": "$120" },
    "2.5 inch": { "price": "$145" }
  }
}
```

---

## ğŸ§‘â€ğŸ’» Author

Ankit Vyas

---

## ğŸ“„ License

MIT License
